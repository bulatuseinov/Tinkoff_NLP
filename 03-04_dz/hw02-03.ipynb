{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorboard import summary as summary_lib\n",
    "from pymystem3 import Mystem\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import string\n",
    "import razdel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с данными (1 балл)\n",
    "\n",
    "Загрузите датасет, с которым вы работали во время соревнования на kaggle. Преобразуйте его в формат, удобный для обучения модели. В качетсве фичей используйте эмбединги слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "\n",
    "def tokkenize_razdel(text):\n",
    "    return [token.text for token in razdel.tokenize(text)]\n",
    " \n",
    "def token(text):\n",
    "    result = []\n",
    "    for doc in text:    \n",
    "        doc = tokkenize_razdel(doc)\n",
    "        result.append(doc)        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSTARTT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokkenize_razdel('SSTARTT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "data = pd.read_csv('train.csv', index_col= False)\n",
    "\n",
    "Y = np.array(data.label)\n",
    "X = np.array(data.text)\n",
    "\n",
    "x_train_variable = \" SSTARTT \" + X\n",
    "y_train = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_id = 0\n",
    "oov_id = 'UNK'\n",
    "index_offset = 2\n",
    "sentence_size = 30\n",
    "vocab_size = 5000\n",
    "embedding_size = 20\n",
    "model_dir = tempfile.mkdtemp()\n",
    "\n",
    "def preprocess_vectorize(data):\n",
    "    data = token(data)\n",
    "    \n",
    "    for element in data:\n",
    "        element = ' '.join(element)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words = vocab_size, \n",
    "                          filters ='!\"$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', \n",
    "                          lower=True, \n",
    "                          oov_token= oov_id)\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    data = tokenizer.texts_to_sequences(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 163 ms, total: 16.2 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_variable = preprocess_vectorize(x_train_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X, Y for train: 89973 , 89973\n",
      "X, Y for validation: 22494 , 22494\n"
     ]
    }
   ],
   "source": [
    "X_train_variable, X_val_variable, Y_train, Y_val = train_test_split(x_train_variable, y_train, test_size=0.2, random_state=42)\n",
    "print(\"X, Y for train:\", len(X_train_variable), \",\", Y_train.size)\n",
    "print(\"X, Y for validation:\", len(X_val_variable),\",\", Y_val.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train_variable, maxlen= sentence_size, padding = 'post',truncating = 'post')\n",
    "X_val = pad_sequences(X_val_variable, maxlen= sentence_size, padding = 'post',truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len_train = np.array([min(len(x), sentence_size) for x in X_train_variable])\n",
    "x_len_test = np.array([min(len(x), sentence_size) for x in X_val_variable])\n",
    "\n",
    "def parser(x, length, y):\n",
    "    features = {\"x\": x, \"len\": length}\n",
    "    return features, y\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_train, x_len_train, Y_train))\n",
    "    dataset = dataset.shuffle(buffer_size=len(X_train_variable))\n",
    "    dataset = dataset.batch(50)\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_val, x_len_test, Y_val))\n",
    "    dataset = dataset.batch(50)\n",
    "    dataset = dataset.map(parser)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/bow_sparse', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13c42ca20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "column = tf.feature_column.categorical_column_with_identity('x', vocab_size)\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=[column], model_dir=os.path.join(model_dir, 'bow_sparse'),n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifiers = {}\n",
    "def train_and_evaluate(classifier):\n",
    "    # Save a reference to the classifier to run predictions later\n",
    "    all_classifiers[classifier.model_dir] = classifier\n",
    "    classifier.train(input_fn=train_input_fn, steps=1500)\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "    predictions = np.array([p['class_ids'][0] for p in classifier.predict(input_fn=eval_input_fn)])\n",
    "        \n",
    "    # Reset the graph to be able to reuse name scopes\n",
    "    tf.reset_default_graph() \n",
    "    # Add a PR summary in addition to the summaries that the classifier writes\n",
    "#     pr = summary_lib.pr_curve('precision_recall', predictions=predictions, labels=y_test.astype(bool), num_thresholds=21)\n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(os.path.join(classifier.model_dir, 'eval'), sess.graph)\n",
    "#         writer.add_summary(sess.run(pr), global_step=0)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/bow_sparse/model.ckpt.\n",
      "INFO:tensorflow:loss = 54.930614, step = 1\n",
      "INFO:tensorflow:global_step/sec: 172.535\n",
      "INFO:tensorflow:loss = 32.252804, step = 101 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 1074.5\n",
      "INFO:tensorflow:loss = 21.3676, step = 201 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1062.61\n",
      "INFO:tensorflow:loss = 24.701527, step = 301 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1063.23\n",
      "INFO:tensorflow:loss = 18.72807, step = 401 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1003.7\n",
      "INFO:tensorflow:loss = 15.614145, step = 501 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1015.38\n",
      "INFO:tensorflow:loss = 10.980184, step = 601 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 989.472\n",
      "INFO:tensorflow:loss = 18.151867, step = 701 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1012.56\n",
      "INFO:tensorflow:loss = 15.706837, step = 801 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1002.9\n",
      "INFO:tensorflow:loss = 18.42295, step = 901 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1019.91\n",
      "INFO:tensorflow:loss = 17.565857, step = 1001 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 969.432\n",
      "INFO:tensorflow:loss = 19.052967, step = 1101 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 935.944\n",
      "INFO:tensorflow:loss = 10.537562, step = 1201 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1015.81\n",
      "INFO:tensorflow:loss = 20.552282, step = 1301 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1056.21\n",
      "INFO:tensorflow:loss = 14.267146, step = 1401 (0.095 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/bow_sparse/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12.703933.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-17-19:54:49\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/bow_sparse/model.ckpt-1500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-17-19:54:50\n",
      "INFO:tensorflow:Saving dict for global step 1500: accuracy = 0.8694763, average_loss = 0.29919642, global_step = 1500, loss = 14.9558325\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1500: /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/bow_sparse/model.ckpt-1500\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/bow_sparse/model.ckpt-1500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model (1 балл)\n",
    "\n",
    "Реализуйте модель со следующими слоями, идущими в указанном порядке:\n",
    "- Conv1D, activation='relu'\n",
    "- MaxPooling1D\n",
    "- Dense\n",
    "\n",
    "Параметры модели подберите сами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = tf.feature_column.categorical_column_with_identity('x', vocab_size)\n",
    "word_embedding_column = tf.feature_column.embedding_column(column, dimension=embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/cnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1435d2ba8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "head = tf.contrib.estimator.multi_label_head(n_classes=3)\n",
    "\n",
    "def cnn_model_fn(features, labels, mode, params):    \n",
    "    input_layer = tf.contrib.layers.embed_sequence(\n",
    "        features['x'], vocab_size, embedding_size,\n",
    "        initializer=params['embedding_initializer'])\n",
    "    \n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "\n",
    "    conv = tf.layers.conv1d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Global Max Pooling\n",
    "    pool = tf.reduce_max(input_tensor=conv, axis=1)\n",
    "    \n",
    "    hidden = tf.layers.dense(inputs=pool, units=250, activation=tf.nn.relu)\n",
    "    \n",
    "\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=hidden, units=3)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    \n",
    "    def _train_op_fn(loss):\n",
    "        return optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "    print(\"EXEXEXEXE\")\n",
    "\n",
    "    labels = tf.one_hot(labels, 3)\n",
    "  \n",
    "    return head.create_estimator_spec(\n",
    "        features=features,\n",
    "        labels=labels,\n",
    "        mode=mode,\n",
    "        logits=logits, \n",
    "        train_op_fn=_train_op_fn)\n",
    "  \n",
    "params = {'embedding_initializer': tf.random_uniform_initializer(-1.0, 1.0)}\n",
    "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
    "                                        model_dir=os.path.join(model_dir, 'cnn'),\n",
    "                                        params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "EXEXEXEXE\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/cnn/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/cnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.12920953, step = 20001\n",
      "INFO:tensorflow:global_step/sec: 110.123\n",
      "INFO:tensorflow:loss = 0.14024536, step = 20101 (0.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.67\n",
      "INFO:tensorflow:loss = 0.08002748, step = 20201 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.525\n",
      "INFO:tensorflow:loss = 0.13519835, step = 20301 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.921\n",
      "INFO:tensorflow:loss = 0.052825946, step = 20401 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.657\n",
      "INFO:tensorflow:loss = 0.16248485, step = 20501 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.39\n",
      "INFO:tensorflow:loss = 0.08627862, step = 20601 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.182\n",
      "INFO:tensorflow:loss = 0.102252424, step = 20701 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.496\n",
      "INFO:tensorflow:loss = 0.065586545, step = 20801 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.269\n",
      "INFO:tensorflow:loss = 0.08234919, step = 20901 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.059\n",
      "INFO:tensorflow:loss = 0.10964325, step = 21001 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.13\n",
      "INFO:tensorflow:loss = 0.08853728, step = 21101 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.997\n",
      "INFO:tensorflow:loss = 0.19120045, step = 21201 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.753\n",
      "INFO:tensorflow:loss = 0.06605078, step = 21301 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.135\n",
      "INFO:tensorflow:loss = 0.058358736, step = 21401 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.705\n",
      "INFO:tensorflow:loss = 0.15730605, step = 21501 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.52\n",
      "INFO:tensorflow:loss = 0.04578962, step = 21601 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.402\n",
      "INFO:tensorflow:loss = 0.17047226, step = 21701 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.77\n",
      "INFO:tensorflow:loss = 0.083700106, step = 21801 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.207\n",
      "INFO:tensorflow:loss = 0.12770455, step = 21901 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.939\n",
      "INFO:tensorflow:loss = 0.039942373, step = 22001 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.795\n",
      "INFO:tensorflow:loss = 0.10690944, step = 22101 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.267\n",
      "INFO:tensorflow:loss = 0.06685765, step = 22201 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.796\n",
      "INFO:tensorflow:loss = 0.067743115, step = 22301 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.853\n",
      "INFO:tensorflow:loss = 0.084493615, step = 22401 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.354\n",
      "INFO:tensorflow:loss = 0.09256853, step = 22501 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.329\n",
      "INFO:tensorflow:loss = 0.09508161, step = 22601 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.847\n",
      "INFO:tensorflow:loss = 0.0377429, step = 22701 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.89\n",
      "INFO:tensorflow:loss = 0.054178957, step = 22801 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.145\n",
      "INFO:tensorflow:loss = 0.1656749, step = 22901 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.136\n",
      "INFO:tensorflow:loss = 0.061162747, step = 23001 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.462\n",
      "INFO:tensorflow:loss = 0.21588024, step = 23101 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.623\n",
      "INFO:tensorflow:loss = 0.054424915, step = 23201 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.547\n",
      "INFO:tensorflow:loss = 0.07142679, step = 23301 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.545\n",
      "INFO:tensorflow:loss = 0.07974356, step = 23401 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.98\n",
      "INFO:tensorflow:loss = 0.13107873, step = 23501 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.076\n",
      "INFO:tensorflow:loss = 0.14179315, step = 23601 (0.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.462\n",
      "INFO:tensorflow:loss = 0.08920454, step = 23701 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.738\n",
      "INFO:tensorflow:loss = 0.18222858, step = 23801 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.335\n",
      "INFO:tensorflow:loss = 0.06287254, step = 23901 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.133\n",
      "INFO:tensorflow:loss = 0.12308373, step = 24001 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.807\n",
      "INFO:tensorflow:loss = 0.11994802, step = 24101 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.717\n",
      "INFO:tensorflow:loss = 0.06985629, step = 24201 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.475\n",
      "INFO:tensorflow:loss = 0.14652307, step = 24301 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.623\n",
      "INFO:tensorflow:loss = 0.068118155, step = 24401 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.383\n",
      "INFO:tensorflow:loss = 0.104836404, step = 24501 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.604\n",
      "INFO:tensorflow:loss = 0.05548671, step = 24601 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.896\n",
      "INFO:tensorflow:loss = 0.044305425, step = 24701 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.349\n",
      "INFO:tensorflow:loss = 0.12050825, step = 24801 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.223\n",
      "INFO:tensorflow:loss = 0.07720114, step = 24901 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.804\n",
      "INFO:tensorflow:loss = 0.048621975, step = 25001 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.581\n",
      "INFO:tensorflow:loss = 0.028354889, step = 25101 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.135\n",
      "INFO:tensorflow:loss = 0.04791955, step = 25201 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.864\n",
      "INFO:tensorflow:loss = 0.058939077, step = 25301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.191\n",
      "INFO:tensorflow:loss = 0.08064298, step = 25401 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.385\n",
      "INFO:tensorflow:loss = 0.026004717, step = 25501 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.905\n",
      "INFO:tensorflow:loss = 0.104846336, step = 25601 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.219\n",
      "INFO:tensorflow:loss = 0.12472576, step = 25701 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.348\n",
      "INFO:tensorflow:loss = 0.16365877, step = 25801 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.213\n",
      "INFO:tensorflow:loss = 0.05116597, step = 25901 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.018\n",
      "INFO:tensorflow:loss = 0.1018595, step = 26001 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.533\n",
      "INFO:tensorflow:loss = 0.057726074, step = 26101 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.149\n",
      "INFO:tensorflow:loss = 0.13078384, step = 26201 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.806\n",
      "INFO:tensorflow:loss = 0.12871704, step = 26301 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.545\n",
      "INFO:tensorflow:loss = 0.14654665, step = 26401 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.578\n",
      "INFO:tensorflow:loss = 0.07379654, step = 26501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.775\n",
      "INFO:tensorflow:loss = 0.044024114, step = 26601 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.395\n",
      "INFO:tensorflow:loss = 0.10591977, step = 26701 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.805\n",
      "INFO:tensorflow:loss = 0.06006944, step = 26801 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.247\n",
      "INFO:tensorflow:loss = 0.05274706, step = 26901 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.146\n",
      "INFO:tensorflow:loss = 0.12822725, step = 27001 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.198\n",
      "INFO:tensorflow:loss = 0.0808236, step = 27101 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.651\n",
      "INFO:tensorflow:loss = 0.04705702, step = 27201 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.116\n",
      "INFO:tensorflow:loss = 0.062675305, step = 27301 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.3\n",
      "INFO:tensorflow:loss = 0.10452288, step = 27401 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.185\n",
      "INFO:tensorflow:loss = 0.069183655, step = 27501 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.446\n",
      "INFO:tensorflow:loss = 0.08737571, step = 27601 (0.367 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 292.046\n",
      "INFO:tensorflow:loss = 0.06679263, step = 27701 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.938\n",
      "INFO:tensorflow:loss = 0.14652485, step = 27801 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.572\n",
      "INFO:tensorflow:loss = 0.06638595, step = 27901 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.705\n",
      "INFO:tensorflow:loss = 0.07143498, step = 28001 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.308\n",
      "INFO:tensorflow:loss = 0.024092149, step = 28101 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.761\n",
      "INFO:tensorflow:loss = 0.044760257, step = 28201 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.141\n",
      "INFO:tensorflow:loss = 0.06301949, step = 28301 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.979\n",
      "INFO:tensorflow:loss = 0.10463678, step = 28401 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.178\n",
      "INFO:tensorflow:loss = 0.051904365, step = 28501 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.544\n",
      "INFO:tensorflow:loss = 0.03164601, step = 28601 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.561\n",
      "INFO:tensorflow:loss = 0.07137704, step = 28701 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.755\n",
      "INFO:tensorflow:loss = 0.06631312, step = 28801 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.781\n",
      "INFO:tensorflow:loss = 0.07939121, step = 28901 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.066\n",
      "INFO:tensorflow:loss = 0.031273775, step = 29001 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.325\n",
      "INFO:tensorflow:loss = 0.08255216, step = 29101 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.261\n",
      "INFO:tensorflow:loss = 0.0639128, step = 29201 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.524\n",
      "INFO:tensorflow:loss = 0.031472813, step = 29301 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.245\n",
      "INFO:tensorflow:loss = 0.09181187, step = 29401 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.949\n",
      "INFO:tensorflow:loss = 0.03756589, step = 29501 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.202\n",
      "INFO:tensorflow:loss = 0.077797316, step = 29601 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.012\n",
      "INFO:tensorflow:loss = 0.055974875, step = 29701 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.282\n",
      "INFO:tensorflow:loss = 0.106932834, step = 29801 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.007\n",
      "INFO:tensorflow:loss = 0.024172692, step = 29901 (0.403 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/cnn/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.05815313.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "EXEXEXEXE\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-17-20:14:33\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/cnn/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-17-20:14:34\n",
      "INFO:tensorflow:Saving dict for global step 30000: auc = 0.955022, auc_precision_recall = 0.92898905, average_loss = 0.37220174, global_step = 30000, loss = 0.3722665\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: /var/folders/zw/2w6s_cjx4h9dj9fjz5t8tr800000gn/T/tmpb37d5_l5/cnn/model.ckpt-30000\n"
     ]
    }
   ],
   "source": [
    "cnn_classifier.train(input_fn=train_input_fn, steps=10000 )\n",
    "eval_results = cnn_classifier.evaluate(input_fn=eval_input_fn)\n",
    "prediction = cnn_classifier.predict(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model (1 балл)\n",
    "\n",
    "Реализуйте модель со следующими слоями, идущими в указанном порядке:\n",
    "- RNN\n",
    "- Dense\n",
    "\n",
    "Параметры модели подберите сами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model (1 балл)\n",
    "\n",
    "Реализуйте модель со следующими слоями, идущими в указанном порядке:\n",
    "- LSTM\n",
    "- Dense\n",
    "\n",
    "Параметры модели подберите сами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните все три реализованные модели по времени и по качеству классификации. Какая лучше? Как думаете, почему?\n",
    "\n",
    "<b>Вывод:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model (2 балла)\n",
    "\n",
    "Реализуйте модель со следующими слоями, идущими в указанном порядке:\n",
    "- Conv1D, activation='relu'\n",
    "- MaxPooling1D\n",
    "- RNN\n",
    "- Dense\n",
    "\n",
    "Параметры для Conv1D, MaxPooling1D и RNN подберите сами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout (1 балл)\n",
    "\n",
    "Добавьте dropout к baseline моделе. Пример модефицированной модели:\n",
    "- Dropout\n",
    "- Conv1D, activation='relu'\n",
    "- MaxPooling1D\n",
    "- RNN\n",
    "- Dense\n",
    "\n",
    "Подберите параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшило ли результат классификации использование Dropout? Как думаете, почему?\n",
    "\n",
    "<b>Вывод:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional (1 балл)\n",
    "\n",
    "Вместо RNN в первой модели используйте biRNN. Пример модефецированной модели:\n",
    "- Conv1D, activation='relu'\n",
    "- MaxPooling1D\n",
    "- biRNN\n",
    "- Dense\n",
    "\n",
    "Подберите параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дало ли буст использовании biRNN вместо RNN? Сильный? Как думаете, почему?\n",
    "\n",
    "<b>Вывод:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model (2 балла)\n",
    "\n",
    "Подберите архитектуру сети, используя сверточные слои и слои макспулинга и превзойдите качество полносвязной сети.\n",
    "\n",
    "Подберите архитектуру сети, используя следующие типы слоев:\n",
    "- Conv1D\n",
    "- MaxPooling1D\n",
    "- RNN\n",
    "- LSTM\n",
    "- GRU\n",
    "- Dropout\n",
    "- Dense\n",
    "\n",
    "Можно использовать любые из описанных слоев в любом количестве и в любом порядке. Не обязательно использовать все описанные слои. \n",
    "\n",
    "Настройте параметры. Превзойдите лучшее качество, полученное раннее. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

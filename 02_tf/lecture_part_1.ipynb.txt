{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL crash course [theoretical part]\n",
    "\n",
    "    Сегодня мы познакомимся с основами DL\n",
    "\n",
    "- **forward pass**\n",
    "    - лосс\n",
    "    - активации    \n",
    "- **backward pass**\n",
    "    - градиентный спуск\n",
    "    - backpropagation\n",
    "    - оптимизаторы и батчевание\n",
    "- инициализация\n",
    "\n",
    "    \n",
    "Эти концепции мы изучим на примере простой полносвязной сети.\n",
    "\n",
    "\n",
    "## Материалы\n",
    "\n",
    "Эти материалы точно стоит посмотреть. Особенно если что-то не понятно.\n",
    "\n",
    "1.[ML crash course with TF API {Google}](https://developers.google.com/machine-learning/crash-course/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Полносвязная нейронная сеть\n",
    "\n",
    "**[Часть 1.1]**\n",
    "\n",
    "### Forward pass\n",
    "\n",
    "(прямой проход: вычисление значения нейронов с фиксированными параметрами модели)\n",
    "\n",
    "* На рисунке изображена очень простая нейросеть, имеющая один скрытый слой, 2 признака на входе, одно значение на выходе.\n",
    "\n",
    "\n",
    "* При прямом проходе выходное значение сети вычисляется для каждого примера входных данных отдельно. Например, в данном случае для значения входных признаков (40, 0) получаем выходное значение 0. \n",
    "\n",
    "\n",
    "* Стрелочки, связывающие входной слой со скрытым слоем, обозначают веса, с которыми значения из входного слоя складываются для получения соответствующего значения на нейроне скрытого слоя. Таких весов между входным слоем и скрытым слоем всего 4 на картинке. Общепринятое название этих весов **\"п а р а м е т р ы\"** модели. Именно они и подбираются в процессе обучения модели.\n",
    "\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1544476981/forward_a6lbal.png\">\n",
    "\n",
    "Давайте посмотрим на это с помощью `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один сэмпл входных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array([40,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "веса, где `node0`, `node1` -- нейроны скрытого слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'node0':([1,1]),\n",
    "          'node1':([1,-1]),\n",
    "          'output':([1,-1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте вычислим значение `node0`, `node1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 40]\n"
     ]
    }
   ],
   "source": [
    "node0_value = (input_data * weights['node0']).sum()\n",
    "node1_value = (input_data * weights['node1']).sum()\n",
    "\n",
    "# для удобства положим эти значения в массив\n",
    "hidden_layer_values = np.array([node0_value,node1_value])\n",
    "\n",
    "print(hidden_layer_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вычислим `output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = (hidden_layer_values * weights['output']).sum()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "* Предложите как можно делать те же вычисления только используя матричные перемножения.\n",
    "\n",
    "* Напишите на листочке какие матрицы потребовалось бы ввести в данном случае и как происходили бы перемножения.\n",
    "\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/dynamic_resizing_neural_network_4_obs.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**По итогам части 1**\n",
    "    \n",
    "    - узнали что такое параметры полносвязной нейросети\n",
    "    - узнали как полносвязная нейросеть с фиксированными параметрами делает предсказание\n",
    "    - поняли при чем тут матричные перемножения\n",
    "    \n",
    "  ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Часть 1.2]**\n",
    "\n",
    "## Loss (или функция потерь)\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/cross_entropy.png\">\n",
    "\n",
    "[доп материал по теме](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)\n",
    "\n",
    "**Функция потерь** - в нашем случае это дифференцируемая функция $f(predictions, labels)$, где `predictions` - предсказания модели (т.е. выходы последнего слоя), а `labels` - истинный ответ. $f$ показывает насколько хорошо согласуются предсказания модели с истинными ответами. Чем меньше значение функции потерь тем лучше модель делает предсказание на данной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наиболее часто встречающиеся лосс-функции\n",
    "\n",
    "* **Задача классификации**\n",
    "    * Cross-entropy (log-loss, negative log likelihood)\n",
    "    * Hinge loss\n",
    "* **Задача регрессии**\n",
    "    * MSE\n",
    "    * Huber (лучше работает с выбросами, чем MSE)\n",
    "    \n",
    "При работе с задачами, связанными с текстами, чаще работаем с задачей классификации. Поэтому поброднее про `cross-entropy loss`.\n",
    "\n",
    "**Кросс-энтропия** предназначена для оценки моделей, которые порождают распределение вероятностей принадлежности объекта к классам (в данном примере всего $M$ классов). В случае бинарной классификации, как в самом первом примере, функция также применима.\n",
    "\n",
    "$$\\Large Loss_{cross\\_entropy} = - \\sum_{c=0}^{M} y_{o,c} \\cdot log(\\hat{y}_{o,c})$$\n",
    "\n",
    "* $M$ - количество классов (dog, cat, fish)\n",
    "* $log$ - натуральный логарифм\n",
    "* $y$ - бинарный индикатор (1, если лейбл класса $c$ корректен для наблюдения $o$; иначе 0).\n",
    "* $\\hat{y}$ - предсказанная вероятность принадлежности наблюдения $o$ к классу $c$.\n",
    "\n",
    "\n",
    "**Как из выходов последнего слоя получать только значения в интервале 0..1?**\n",
    "- Используем sigmoid или softmax на выходные значения нейронов (смотри следующую часть). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Часть 1.3]**\n",
    "\n",
    "## Функции активации\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1200/1*RD0lIYqB5L2LrI2VTIZqGw.png\" width=700>\n",
    "\n",
    "\n",
    "[материалы по теме](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html)\n",
    "\n",
    "Чтобы аппроксиматор действительно мог быть универсальным, чтобы было возможно аппроксимировать не только линейные функции применяют функции активации. Подбробнее про разные функции можно почитать в материалах по теме. Но есть минимальный набор.\n",
    "\n",
    "**TLDR:** \n",
    "«Какой тип активации я должен использовать?» \n",
    "- Используйте **ReLU**, будьте осторожны с learning_rate и постарайтесь контролировать долю «мертвых» нейронов в сети. Если \"мертвых\" нейронов слишком много, попробуйте **Leaky ReLU**. Старайтесь не использовать **sigmoid** и **tanh**.\n",
    "\n",
    "---\n",
    "\n",
    "* **Sigmoid**\n",
    "    - ${\\displaystyle \\sigma={\\frac {1}{1+e^{-x}}}}$\n",
    "    - $\\sigma'(x) = \\sigma(x) \\cdot (1-\\sigma(x))$\n",
    "    - Выходит что при слишком больших активациях x или при слишком малых активациях x в связи со значением производной градиенты оказываются очень маленькими и сеть обучается медленно или вообще перестает обучаться (vanishing gradients).\n",
    "    \n",
    "---  \n",
    "* **Tanh**\n",
    "    - ${\\displaystyle f(x)= \\frac{e^{2x}-1}{e^{2x}+1}}$\n",
    "    - $f'(x) = 1-tanh(x)^2 \\le 1.0$\n",
    "    - Можно показать, что максимальное значение градиентов для tanh больше, чем для sigmoid, таким образом, проблема затухающих градиентов для tanh ощущается чуть меньше, но все равно присутствует, т.к. $max(tanh'(x))\\le 1$\n",
    "\n",
    "---\n",
    "* **ReLU (Rectified Linear Unit)**\n",
    "    - ${\\displaystyle f(x) = max(0,x)}$\n",
    "    - Обрубает течение градиентов для всех нейронов, активация которых меньше 0\n",
    "---\n",
    "\n",
    "* **Parametric (Leaky) ReLUs (PReLUs)**\n",
    "    - $f(x)={\\begin{cases}x&{\\mbox{if }}x>0\\\\ax&{\\mbox{otherwise}}\\end{cases}}$\n",
    "    - Параметр $a$ обучается вместе с другими параметрами сети\n",
    "---\n",
    "\n",
    "* **ELU**\n",
    "\n",
    "    - ${\\displaystyle f(x)={\\begin{cases}x&{\\mbox{if }}x\\geq 0\\\\a(e^{x}-1)&{\\mbox{otherwise}}\\end{cases}}}$\n",
    "    - $a\\geq 0 $ -- условие на значения гиперпараметра $a$ (подбирается ручками)\n",
    "    - _ELU_ [дает лучшие](https://arxiv.org/abs/1511.07289) результаты на классификации, чем _ReLU_\n",
    " \n",
    "---\n",
    "\n",
    "* **Maxout**\n",
    "   - $f(x) = max(w^T_1 x+b_1,w^T_2 x+b_2)$\n",
    "   - _ReLU_ & _Leaky ReLU_ - частные случаи (например для ReLU $w_1,b_1=0$)\n",
    "   \n",
    "**Чтиво для сурового вечера будней**\n",
    " [кратко и ясно про активации](http://cs231n.github.io/neural-networks-1/#actfun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[Часть 2.1]**\n",
    "\n",
    "# Backward pass\n",
    "\n",
    "<img src=\"https://pp.userapi.com/c638826/v638826802/6096c/yi-mZgfhkmg.jpg\" width=500>\n",
    "\n",
    "\n",
    "Т.к. loss $f$ зависит от `predictions`, а `predictions` зависят от значений параметровов нейросети, то можно попробовать найти такие параметры нейросети, при которых функция $f$ будет иметь наименьшее значение. Т.е. найти параметры нейросети, соответствующие глобальному минимуму loss-функции.\n",
    "\n",
    "Для этого применяется [метод градиентного спуска](http://www.machinelearning.ru/wiki/index.php?title=Метод_градиентного_спуска).\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/6QlTwkigqg4yk/giphy.gif\">\n",
    "\n",
    "\n",
    "\n",
    "## Обновление весов\n",
    "\n",
    "#### Как ошибка распространяется по сети?\n",
    "\n",
    "Так-как в DL обычно много слоев, то одни параметры зависят от других и становится возможным применение [chain-rule](https://en.wikipedia.org/wiki/Chain_rule) или дифференцирование сложной функции. Совмещение этих двух вещей порождает алгоритм `backpropagation` - или обратное распространение ошибки.\n",
    "\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*FceBJSJ7j8jHjb4TmLV0Ew.png\" width=600>\n",
    "\n",
    "$$\\Large Loss \\rightarrow outputs \\rightarrow hidden\\_layers \\rightarrow inputs$$\n",
    "\n",
    "#### Как меняем параметры сети?\n",
    "\n",
    "В самом простом случае используется простой **градиентный спуск**, т.е. параметры меняются по правилу:\n",
    "\n",
    "\n",
    "$$\\Large W = W - \\eta \\cdot \\nabla J_W(W, X, Y)$$\n",
    "\n",
    "где \n",
    "* $J(W, X, Y)$ -- функция потерь на датасете (X, Y) c моделью с параметрами $W$\n",
    "* $\\eta$ -- learning_rate (шаг обучения)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Часть 2.2]**\n",
    "\n",
    "## Оптимизаторы и батчевание\n",
    "\n",
    "### Виды оптимайзеров\n",
    "\n",
    "Выбор оптимайзера и его параметров важны. Разные оптимайзеры гарантируют разную сходимость и скорость сходимости.\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/1600/1*SjtKOauOXFVjWRR7iCtHiA.gif'>\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/1600/1*XVFmo9NxLnwDr3SxzKy-rA.gif'>\n",
    "\n",
    "#### 1. SGD (stochastic gradient descent)\n",
    "\n",
    "$$\\Large W = W - \\eta \\cdot \\nabla J_W(W, x_i, y_i)$$\n",
    "\n",
    "Считаем градиенты и меняем параметры на одном конкретном примере из датасета\n",
    "\n",
    "\n",
    "<img src=\"https://www.jeremyjordan.me/content/images/2018/02/Screen-Shot-2018-02-24-at-11.47.09-AM.png\" width=700>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### 2. mini-batch GD\n",
    "\n",
    "$$\\Large W = W - \\eta \\cdot \\nabla J_W(W, x_{i:i+n}, y_{i:i+n})$$\n",
    "\n",
    "Считаем градиенты и меняем параметры на **подмножестве примеров** из датасета (называемом мини-батч или просто батч)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### 3. Momentum idea\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/842/1*veF27JZksCT0OWrgIP2SxA.png\" width=700>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "\\Large v_t = \\gamma v_{t-1} + \\eta \\cdot \\nabla J_W(W, x_{i:i+n}, y_{i:i+n})\\\\\n",
    "\\Large W = W - v_t\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "* Считаем градиенты и меняем параметры на **подмножестве примеров** из датасета (называемом мини-батч или просто батч)\n",
    "* $\\gamma$ примерно порядка 0.9\n",
    "* Учитываем прошлое направление градиента и стараемся на слишком отклоняться от него\n",
    "\n",
    "\n",
    "<font color='blue'>Другие оптимизаторы, использующие модифицированную идею momentum</font>\n",
    "* Nesterov accelerated gradient (NAG)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Adaptive learning rate idea\n",
    "\n",
    "Меняем learning_rate в процессе обучения\n",
    "\n",
    " ### Adagrad (adaptive gradient)\n",
    " Главные фишки:\n",
    " * Обновление каждого параметра нейросети со своим learning_rate\n",
    " * Обновление learning_rate базируюсь на прошлых значениях градиента\n",
    "     \n",
    "$$\n",
    "\\begin{array}{c}\n",
    "\\Large g_{t,i} = \\nabla J_{W_{i}}(W, x, y)\\\\\n",
    "\\Large W_{t, i} = W_{t-1,i} - \\frac{\\eta}{\\sqrt{\\sum\\limits_{k=0}^{k=t} g_{k, i}^2} +\\epsilon}\\cdot g_{t, i}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<font color='blue'>Оптимизаторы, использующие идею adaptive lr:</font>\n",
    "* **Adadelta** (расширение Adagrad: рассматриваем не все прошлые квадраты градиентов, а смотрим только на последние n; считаем экспоненциальное скользящее среднее для квадратов градиентов; вместо фиксированного $\\eta$ используем корень из скользящего среднего)\n",
    "* **RMSprop** (по сути урезанная Adadelta: все то же экспоненциальное среднее, но $\\eta$ фиксирована)\n",
    "\n",
    "### 5. Совмещение идеи адаптивного шага обучения и момента\n",
    "\n",
    "#### ADAM\n",
    "\n",
    "* Считаем экспоненциальное скользящее среднее теперь уже и для самих градиентов (аналог момента) и для их квадратов (аналог подхода с adaptive_lr)\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "\\Large m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t\\\\\n",
    "\\Large v_t = \\beta_1 \\cdot v_{t-1} + (1 - \\beta_1) \\cdot g_t\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "* Делаем поправку скользящих средних на смещенность:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "\\Large \\hat{m}_t = \\frac{m_t}{1-\\beta_1^{t}} \\\\\n",
    "\\Large \\hat{v}_t = \\frac{v_t}{1-\\beta_2^{t}}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "* Обновляем каждый параметр со своим lr и со своим моментом-градиентом\n",
    "\n",
    "$$\\Large W_{t+1, i} = W_{t, i} - \\frac{\\eta}{\\sqrt{\\hat{v}_{t,i}}+\\epsilon}\\cdot \\hat{m}_{t,i}$$\n",
    "\n",
    "\n",
    "<font color='blue'>Другие оптимизаторы, совмещающие обе идеи:</font>\n",
    "* **AdaMax** (учитывает L2 норму вектора градиента)\n",
    "* **Nadam** (NAG + ADAM)\n",
    "* **AMSGrad** (ADAM, с модификацией: $ \\hat{v}_t = max(\\hat{v_{t-1}}, v_t)$)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Про инициализацию переменных\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*_wS_ul0act9fCT-b7SuONQ.png\" width=400>\n",
    "\n",
    "### <font color='blue'>Что первое приходит в голову?</font>\n",
    "\n",
    "**1. Инициализация всех весов нулями**\n",
    "\n",
    "Предположим мы сделали это. В таком случае **ваша модель становится эквивалентна линейной модели**. Когда вы устанавливаете все веса в 0, производная по функции потерь одинакова для каждого $w_i$, таким образом, все веса имеют одинаковые значения и в последующей итерации. Это делает нейроны в сети симметричными. Так продолжается для всех n итераций, которые вы запускаете. Важно отметить, что установка смещений в 0 не вызовет каких-либо проблем, поскольку ненулевые веса позаботятся о нарушении симметрии, и даже если смещение равно 0, значения в каждом нейроне по-прежнему различаются.\n",
    "\n",
    "**2. Инициализация весов рандомными значениями**\n",
    "\n",
    "Инициализация весов произвольно, после стандартного нормального распределения `np.random.randn (size_n, size_m)` в Python) при работе с (глубокой) сетью потенциально может привести к двум проблемам - исчезающим градиентам или взрывающимся градиентам.\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**1. Xavier**\n",
    "* Xavier Glorot and Yoshua Bengio (2010): [Understanding the difficulty of training deep feedforward neural networks. International conference on artificial intelligence and statistics.](http://www.jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)\n",
    "\n",
    "This initializer is designed to keep the scale of the gradients roughly the same in all layers.\n",
    "\n",
    "* In **uniform** distribution this ends up being the range: $x = \\sqrt{(\\frac{6.}{in + out})}$; $[-x, x]$ \n",
    "* and for **normal** distribution a standard deviation of $\\sqrt{(\\frac{2.}{in + out})}$ is used\n",
    "\n",
    "**2. He, normal**\n",
    "* [He et al (2015)](http://arxiv.org/abs/1502.01852)\n",
    "\n",
    "It draws samples from a **truncated normal distribution centered on 0 with $stddev = \\sqrt{\\frac{2}{in}}$**\n",
    "\n",
    "_Truncated normal distribution is a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than 2 standard deviations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

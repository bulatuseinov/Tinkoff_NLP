{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6iPSmuDbXvq"
   },
   "source": [
    "# CNN для классификации текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN история"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/cats.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хайп вокруг CNN начался с [Alexnet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "<img src=\"img/alexnet.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/2d_convolution.gif\" alt=\"drawing\" width=\"400\"/>\n",
    "<img src=\"img/2d_activation.gif\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "* размер свертки\n",
    "* stride \n",
    "* padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/maxpool.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "* max pooling\n",
    "* average pooling\n",
    "* k-max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN для текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1d_convolution.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### char cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1d_char.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часто комбинируют свертки разного размера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1d_multy.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Хитрости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/residual.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация текста при помощи TensorFlow Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eB6v9qVLT7q4"
   },
   "source": [
    "В этом ноубуке мы разберемся как использовать custom tensorflow estimators для классификации текста. \n",
    "Мы будем использовать tf.Data, tf.Estimator, tf.layers, word2vec эмбеддинги.\n",
    "\n",
    "\n",
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLcya95hbyAk"
   },
   "source": [
    "### The IMDB Dataset\n",
    "\n",
    "<img src=\"img/imdb.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Мы будем использовать датасет IMDB [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/), \n",
    "который состоит из $25,000$ отзывов на популярные фильмы в обучающей выборке, и $25,000$ в тестовой выборке. Мы обучим модель для бинарной классификации, которая предсказывает является ли отзыв о фильме позитивным или негативным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Заимпортим все необходимые бибилиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1523273466121,
     "user": {
      "displayName": "Julian Eisenschlos",
      "photoUrl": "//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg",
      "userId": "112692138304087361987"
     },
     "user_tz": 180
    },
    "id": "hwq4V3xwMbYk",
    "outputId": "12e9efc9-76dd-457a-de65-21b973fa8944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorboard import summary as summary_lib\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras предоставляет возможность легко загружать некоторые датасеты (https://keras.io/datasets/) для удобства тестирования и бенчмаркинга архитектур"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6981,
     "status": "ok",
     "timestamp": 1523273476760,
     "user": {
      "displayName": "Julian Eisenschlos",
      "photoUrl": "//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg",
      "userId": "112692138304087361987"
     },
     "user_tz": 180
    },
    "id": "RStSE6MjAR5s",
    "outputId": "0f50c910-8cc9-4c7b-9a42-cd06daf89df6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 200)\n",
      "x_test shape: (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "sentence_size = 200\n",
    "embedding_size = 50\n",
    "model_dir = tempfile.mkdtemp()\n",
    "\n",
    "# первые индексы в словаре зарезервированы за специальными токенами \n",
    "# для паддинга, начала предложения, и для слов которые не вошли в словарь\n",
    "pad_id = 0\n",
    "start_id = 1\n",
    "oov_id = 2\n",
    "index_offset = 2\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(x_train_variable, y_train), (x_test_variable, y_test) = imdb.load_data(\n",
    "    num_words=vocab_size, start_char=start_id, oov_char=oov_id,\n",
    "    index_from=index_offset)\n",
    "print(len(y_train), \"train sequences\")\n",
    "print(len(y_test), \"test sequences\")\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "x_train = sequence.pad_sequences(x_train_variable, \n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "x_test = sequence.pad_sequences(x_test_variable, \n",
    "                                maxlen=sentence_size,\n",
    "                                truncating='post',\n",
    "                                padding='post', \n",
    "                                value=pad_id)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1BBYudtvq9w"
   },
   "source": [
    "По индексам слов можно получить их исходное представление чтобы посмотреть что было закодировано\n",
    "(например в первом примере из  train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2185,
     "status": "ok",
     "timestamp": 1523274024651,
     "user": {
      "displayName": "Julian Eisenschlos",
      "photoUrl": "//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg",
      "userId": "112692138304087361987"
     },
     "user_tz": 180
    },
    "id": "N08jsWy3vq9x",
    "outputId": "dfd55113-1190-4ac0-8a41-8141286e0360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <PAD>\n",
      "1 <START>\n",
      "2 <OOV>\n",
      "3 the\n",
      "4 and\n",
      "5 a\n",
      "6 of\n",
      "7 to\n",
      "8 is\n",
      "9 br\n",
      "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <OOV> is an amazing actor and now the same being director <OOV> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <OOV> and would recommend it to everyone to watch and the fly <OOV> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <OOV> to the two little <OOV> that played the <OOV> of norman and paul they were just brilliant children are often left out of the <OOV> list i think because the stars that play them all grown up are such a big <OOV> for the whole film but these children are amazing and should be <OOV> for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was <OOV> with us all\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "word_inverted_index = {v + index_offset: k for k, v in word_index.items()}\n",
    "\n",
    "# Первые индексы в словаре зарезервированы для специальных токенов\n",
    "word_inverted_index[pad_id] = '<PAD>'\n",
    "word_inverted_index[start_id] = '<START>'\n",
    "word_inverted_index[oov_id] = '<OOV>'\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(i, word_inverted_index[i])\n",
    "\n",
    "def index_to_text(indexes):\n",
    "    return ' '.join([word_inverted_index[i] for i in indexes])\n",
    "\n",
    "print(index_to_text(x_train_variable[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKhoMPMtTbul"
   },
   "source": [
    "## Tensorflow Estimator\n",
    "\n",
    "В следующей секции мы разберем как создавать кастомные эстиматоры, как их обучать и делать предсказания\n",
    "\n",
    "Детально о создании эстиматоров можно почитать [тут](https://developers.googleblog.com/2017/12/creating-custom-estimators-in-tensorflow.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пайплайн tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFf3Z9Mbvq91"
   },
   "source": [
    "### From arrays to tensors\n",
    "\n",
    "Чтобы иметь возможность подавать данные в Tensorflow для обучения, данные нужно сконвертировать из numpy массивов в Tensors. Мы будем использовать для этого модуль `tf.data.Dataset`.\n",
    "\n",
    "Мы используем функцию `from_tensor_slices` для создания объекта `Dataset`, к которому потом можно применять различные преобразования: перемешивание данных, упаковка в батчи, повторение процесса заданное количество итераций. \n",
    "\n",
    "Пайплайн `tf.data` содержит множество других функций для закрузки данных в модель, в том числе из данных сохраненных на диске. При этом весь менеджмент памяти и другие детали ложатся на tensorflow.\n",
    "\n",
    "Для того, чтобы подавать данные в модель, нужно определить две функции: train_input_fn и eval_input_fn.\n",
    "Одна используется для подачи данных для обучения модели, а вторая для подачи тестовых данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VPLRuDRnvq92"
   },
   "outputs": [],
   "source": [
    "x_len_train = np.array([min(len(x), sentence_size) for x in x_train_variable])\n",
    "x_len_test = np.array([min(len(x), sentence_size) for x in x_test_variable])\n",
    "\n",
    "def parser(x, length, y):\n",
    "    features = {\"x\": x, \"len\": length}\n",
    "    return features, y\n",
    "\n",
    "def train_input_fn():\n",
    "    # Подача данных для обучения\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train, x_len_train, y_train))\n",
    "    dataset = dataset.shuffle(buffer_size=len(x_train_variable))\n",
    "    dataset = dataset.batch(100)\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    # Подача тестовых данных\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_test, x_len_test, y_test))\n",
    "    dataset = dataset.batch(100)\n",
    "    dataset = dataset.map(parser)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwCuemrKvq94"
   },
   "source": [
    "### Бейзлайн\n",
    "\n",
    "Попробуем решить задачу с использованием максимально простой линейной моделью для классификации текстов.\n",
    "Линейная модель неучитывает порядок слов в предложении, поэтому подобные подходы называют Bag-of-Words (BOW, мешок слов).\n",
    "\n",
    "В качестве фичей, подаваемых в модель, мы будем использовать `tf.feature_column`. Тут [хороший туториал](https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html). В качестве модели будем использовать стандартный в TensorFlow `LinearClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1523273591870,
     "user": {
      "displayName": "Julian Eisenschlos",
      "photoUrl": "//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg",
      "userId": "112692138304087361987"
     },
     "user_tz": 180
    },
    "id": "neNiEK31Od96",
    "outputId": "76fe017b-3c1c-4d0d-8973-e797de00118b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpc92phuw8/bow_sparse', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fafdf45c358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "column = tf.feature_column.categorical_column_with_identity('x', vocab_size)\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=[column], model_dir=os.path.join(model_dir, 'bow_sparse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для скоринга модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NMHErNXuBFHr"
   },
   "outputs": [],
   "source": [
    "all_classifiers = {}\n",
    "def train_and_evaluate(classifier):\n",
    "    # Save a reference to the classifier to run predictions later\n",
    "    all_classifiers[classifier.model_dir] = classifier\n",
    "    classifier.train(input_fn=train_input_fn, steps=25000)\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "    predictions = np.array([p['logistic'][0] for p in classifier.predict(input_fn=eval_input_fn)])\n",
    "        \n",
    "    # Reset the graph to be able to reuse name scopes\n",
    "    tf.reset_default_graph() \n",
    "    # Add a PR summary in addition to the summaries that the classifier writes\n",
    "    pr = summary_lib.pr_curve('precision_recall', predictions=predictions, labels=y_test.astype(bool), num_thresholds=21)\n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(os.path.join(classifier.model_dir, 'eval'), sess.graph)\n",
    "        writer.add_summary(sess.run(pr), global_step=0)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 8840
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 268303,
     "status": "ok",
     "timestamp": 1523274992515,
     "user": {
      "displayName": "Julian Eisenschlos",
      "photoUrl": "//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg",
      "userId": "112692138304087361987"
     },
     "user_tz": 180
    },
    "id": "B2O7WOpCpifk",
    "outputId": "9e2e2688-4cb9-4b0b-e427-b1bc85b780de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpc92phuw8/bow_sparse/model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 95.0175\n",
      "INFO:tensorflow:loss = 40.10816, step = 100 (1.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.339\n",
      "INFO:tensorflow:loss = 46.62268, step = 200 (0.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.5269\n",
      "INFO:tensorflow:loss = 39.13281, step = 300 (1.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.316\n",
      "INFO:tensorflow:loss = 22.481607, step = 400 (0.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.361\n",
      "INFO:tensorflow:loss = 22.096165, step = 500 (0.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.78\n",
      "INFO:tensorflow:loss = 22.262148, step = 600 (0.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.4509\n",
      "INFO:tensorflow:loss = 25.274582, step = 700 (1.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.9366\n",
      "INFO:tensorflow:loss = 21.009914, step = 800 (1.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.858\n",
      "INFO:tensorflow:loss = 20.605263, step = 900 (0.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1138\n",
      "INFO:tensorflow:loss = 16.71102, step = 1000 (1.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.703\n",
      "INFO:tensorflow:loss = 14.926933, step = 1100 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.784\n",
      "INFO:tensorflow:loss = 23.080639, step = 1200 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.606\n",
      "INFO:tensorflow:loss = 20.670097, step = 1300 (1.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.029\n",
      "INFO:tensorflow:loss = 22.817305, step = 1400 (0.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.522\n",
      "INFO:tensorflow:loss = 13.612967, step = 1500 (0.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9404\n",
      "INFO:tensorflow:loss = 16.614346, step = 1600 (1.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.004\n",
      "INFO:tensorflow:loss = 24.625042, step = 1700 (0.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.377\n",
      "INFO:tensorflow:loss = 23.792355, step = 1800 (0.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.272\n",
      "INFO:tensorflow:loss = 27.71828, step = 1900 (0.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.92\n",
      "INFO:tensorflow:loss = 13.081557, step = 2000 (1.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.451\n",
      "INFO:tensorflow:loss = 12.770867, step = 2100 (0.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.872\n",
      "INFO:tensorflow:loss = 26.398232, step = 2200 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.2785\n",
      "INFO:tensorflow:loss = 17.088594, step = 2300 (1.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7265\n",
      "INFO:tensorflow:loss = 19.911894, step = 2400 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.104\n",
      "INFO:tensorflow:loss = 20.139385, step = 2500 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.621\n",
      "INFO:tensorflow:loss = 13.249574, step = 2600 (0.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.921\n",
      "INFO:tensorflow:loss = 18.102753, step = 2700 (0.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.712\n",
      "INFO:tensorflow:loss = 17.556442, step = 2800 (0.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.361\n",
      "INFO:tensorflow:loss = 16.250185, step = 2900 (0.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.789\n",
      "INFO:tensorflow:loss = 14.715498, step = 3000 (0.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.42\n",
      "INFO:tensorflow:loss = 16.217693, step = 3100 (0.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.998\n",
      "INFO:tensorflow:loss = 19.912762, step = 3200 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.4612\n",
      "INFO:tensorflow:loss = 15.698632, step = 3300 (1.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.6512\n",
      "INFO:tensorflow:loss = 13.901498, step = 3400 (1.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2064\n",
      "INFO:tensorflow:loss = 12.931274, step = 3500 (1.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.6933\n",
      "INFO:tensorflow:loss = 15.874476, step = 3600 (1.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.605\n",
      "INFO:tensorflow:loss = 11.030011, step = 3700 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.694\n",
      "INFO:tensorflow:loss = 19.666553, step = 3800 (0.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.8299\n",
      "INFO:tensorflow:loss = 15.887408, step = 3900 (1.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.676\n",
      "INFO:tensorflow:loss = 15.541559, step = 4000 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.866\n",
      "INFO:tensorflow:loss = 23.280245, step = 4100 (0.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.0806\n",
      "INFO:tensorflow:loss = 14.884134, step = 4200 (1.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.143\n",
      "INFO:tensorflow:loss = 22.343678, step = 4300 (0.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.958\n",
      "INFO:tensorflow:loss = 15.134683, step = 4400 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.8005\n",
      "INFO:tensorflow:loss = 13.453903, step = 4500 (1.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.154\n",
      "INFO:tensorflow:loss = 18.418938, step = 4600 (0.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.475\n",
      "INFO:tensorflow:loss = 24.451258, step = 4700 (0.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.857\n",
      "INFO:tensorflow:loss = 10.980779, step = 4800 (1.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.089\n",
      "INFO:tensorflow:loss = 15.401147, step = 4900 (0.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.54\n",
      "INFO:tensorflow:loss = 10.288416, step = 5000 (0.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.0835\n",
      "INFO:tensorflow:loss = 20.40998, step = 5100 (1.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.95\n",
      "INFO:tensorflow:loss = 17.547258, step = 5200 (0.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.215\n",
      "INFO:tensorflow:loss = 15.269573, step = 5300 (0.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.59\n",
      "INFO:tensorflow:loss = 12.838654, step = 5400 (0.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.4895\n",
      "INFO:tensorflow:loss = 27.364693, step = 5500 (1.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.47\n",
      "INFO:tensorflow:loss = 10.911566, step = 5600 (0.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.188\n",
      "INFO:tensorflow:loss = 21.165363, step = 5700 (0.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3518\n",
      "INFO:tensorflow:loss = 14.887163, step = 5800 (1.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.184\n",
      "INFO:tensorflow:loss = 12.676159, step = 5900 (0.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.204\n",
      "INFO:tensorflow:loss = 17.767305, step = 6000 (0.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.762\n",
      "INFO:tensorflow:loss = 11.167881, step = 6100 (0.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.1246\n",
      "INFO:tensorflow:loss = 8.375444, step = 6200 (1.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.5608\n",
      "INFO:tensorflow:loss = 7.9420533, step = 6300 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.744\n",
      "INFO:tensorflow:loss = 17.51727, step = 6400 (0.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.613\n",
      "INFO:tensorflow:loss = 21.17768, step = 6500 (0.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.0794\n",
      "INFO:tensorflow:loss = 19.520468, step = 6600 (1.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.206\n",
      "INFO:tensorflow:loss = 20.038996, step = 6700 (0.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.332\n",
      "INFO:tensorflow:loss = 11.289845, step = 6800 (0.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.982\n",
      "INFO:tensorflow:loss = 15.814185, step = 6900 (0.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.2634\n",
      "INFO:tensorflow:loss = 23.985792, step = 7000 (1.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.59\n",
      "INFO:tensorflow:loss = 13.096382, step = 7100 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.073\n",
      "INFO:tensorflow:loss = 15.919574, step = 7200 (0.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.4456\n",
      "INFO:tensorflow:loss = 17.102009, step = 7300 (1.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.243\n",
      "INFO:tensorflow:loss = 19.477537, step = 7400 (0.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.318\n",
      "INFO:tensorflow:loss = 11.917946, step = 7500 (0.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5849\n",
      "INFO:tensorflow:loss = 24.622704, step = 7600 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.501\n",
      "INFO:tensorflow:loss = 27.05259, step = 7700 (0.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.504\n",
      "INFO:tensorflow:loss = 14.630678, step = 7800 (0.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.3205\n",
      "INFO:tensorflow:loss = 14.819658, step = 7900 (1.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 10.8221855, step = 8000 (1.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.96\n",
      "INFO:tensorflow:loss = 12.769693, step = 8100 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.0428\n",
      "INFO:tensorflow:loss = 24.260029, step = 8200 (1.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.23\n",
      "INFO:tensorflow:loss = 13.713766, step = 8300 (0.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.582\n",
      "INFO:tensorflow:loss = 16.495789, step = 8400 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.013\n",
      "INFO:tensorflow:loss = 18.280308, step = 8500 (0.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.4966\n",
      "INFO:tensorflow:loss = 12.383954, step = 8600 (1.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.429\n",
      "INFO:tensorflow:loss = 18.951046, step = 8700 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.737\n",
      "INFO:tensorflow:loss = 17.942965, step = 8800 (1.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.84\n",
      "INFO:tensorflow:loss = 12.424901, step = 8900 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.2056\n",
      "INFO:tensorflow:loss = 13.633533, step = 9000 (1.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.565\n",
      "INFO:tensorflow:loss = 15.753168, step = 9100 (0.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.761\n",
      "INFO:tensorflow:loss = 12.519421, step = 9200 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.1988\n",
      "INFO:tensorflow:loss = 12.143061, step = 9300 (1.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.584\n",
      "INFO:tensorflow:loss = 17.434322, step = 9400 (0.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.877\n",
      "INFO:tensorflow:loss = 11.279705, step = 9500 (0.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.3022\n",
      "INFO:tensorflow:loss = 21.809275, step = 9600 (1.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.483\n",
      "INFO:tensorflow:loss = 16.65943, step = 9700 (0.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.019\n",
      "INFO:tensorflow:loss = 13.633152, step = 9800 (0.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0938\n",
      "INFO:tensorflow:loss = 16.264332, step = 9900 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.216\n",
      "INFO:tensorflow:loss = 15.203236, step = 10000 (0.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.971\n",
      "INFO:tensorflow:loss = 12.725356, step = 10100 (0.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.706\n",
      "INFO:tensorflow:loss = 15.666979, step = 10200 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.238\n",
      "INFO:tensorflow:loss = 11.700146, step = 10300 (0.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.133\n",
      "INFO:tensorflow:loss = 13.390873, step = 10400 (0.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.8438\n",
      "INFO:tensorflow:loss = 15.624109, step = 10500 (1.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.074\n",
      "INFO:tensorflow:loss = 22.584942, step = 10600 (0.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.691\n",
      "INFO:tensorflow:loss = 15.700058, step = 10700 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.0145\n",
      "INFO:tensorflow:loss = 14.15628, step = 10800 (1.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.3861\n",
      "INFO:tensorflow:loss = 13.096333, step = 10900 (1.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.122\n",
      "INFO:tensorflow:loss = 10.190158, step = 11000 (0.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.519\n",
      "INFO:tensorflow:loss = 19.930819, step = 11100 (0.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.376\n",
      "INFO:tensorflow:loss = 16.271818, step = 11200 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.838\n",
      "INFO:tensorflow:loss = 15.102507, step = 11300 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.973\n",
      "INFO:tensorflow:loss = 14.332325, step = 11400 (0.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.388\n",
      "INFO:tensorflow:loss = 14.821831, step = 11500 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.605\n",
      "INFO:tensorflow:loss = 16.70255, step = 11600 (0.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.8809\n",
      "INFO:tensorflow:loss = 16.334959, step = 11700 (1.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.593\n",
      "INFO:tensorflow:loss = 15.312956, step = 11800 (0.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.859\n",
      "INFO:tensorflow:loss = 10.922966, step = 11900 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.2128\n",
      "INFO:tensorflow:loss = 16.286745, step = 12000 (1.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.367\n",
      "INFO:tensorflow:loss = 16.749744, step = 12100 (0.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.203\n",
      "INFO:tensorflow:loss = 13.954891, step = 12200 (0.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.9016\n",
      "INFO:tensorflow:loss = 14.736639, step = 12300 (1.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.325\n",
      "INFO:tensorflow:loss = 7.449106, step = 12400 (0.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.179\n",
      "INFO:tensorflow:loss = 14.044099, step = 12500 (0.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.115\n",
      "INFO:tensorflow:loss = 16.67659, step = 12600 (0.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.033\n",
      "INFO:tensorflow:loss = 26.342585, step = 12700 (0.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.318\n",
      "INFO:tensorflow:loss = 13.497302, step = 12800 (0.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.537\n",
      "INFO:tensorflow:loss = 13.956343, step = 12900 (0.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.534\n",
      "INFO:tensorflow:loss = 14.2940445, step = 13000 (0.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.651\n",
      "INFO:tensorflow:loss = 21.914953, step = 13100 (0.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.004\n",
      "INFO:tensorflow:loss = 17.884039, step = 13200 (0.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.7228\n",
      "INFO:tensorflow:loss = 12.409032, step = 13300 (1.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.821\n",
      "INFO:tensorflow:loss = 21.388235, step = 13400 (0.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.241\n",
      "INFO:tensorflow:loss = 17.895424, step = 13500 (0.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0941\n",
      "INFO:tensorflow:loss = 15.733243, step = 13600 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.584\n",
      "INFO:tensorflow:loss = 13.074326, step = 13700 (0.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.476\n",
      "INFO:tensorflow:loss = 17.046747, step = 13800 (0.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.46\n",
      "INFO:tensorflow:loss = 13.147597, step = 13900 (0.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.1984\n",
      "INFO:tensorflow:loss = 18.440693, step = 14000 (1.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.95\n",
      "INFO:tensorflow:loss = 15.300263, step = 14100 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.982\n",
      "INFO:tensorflow:loss = 15.002202, step = 14200 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.2152\n",
      "INFO:tensorflow:loss = 15.666008, step = 14300 (1.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.321\n",
      "INFO:tensorflow:loss = 18.565783, step = 14400 (0.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0403\n",
      "INFO:tensorflow:loss = 9.572334, step = 14500 (1.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.712\n",
      "INFO:tensorflow:loss = 14.110135, step = 14600 (0.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.86\n",
      "INFO:tensorflow:loss = 8.509796, step = 14700 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3158\n",
      "INFO:tensorflow:loss = 12.453069, step = 14800 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9954\n",
      "INFO:tensorflow:loss = 15.263751, step = 14900 (1.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.411\n",
      "INFO:tensorflow:loss = 12.225959, step = 15000 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.393\n",
      "INFO:tensorflow:loss = 18.78975, step = 15100 (0.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.165\n",
      "INFO:tensorflow:loss = 11.476738, step = 15200 (0.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.473\n",
      "INFO:tensorflow:loss = 10.95596, step = 15300 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.985\n",
      "INFO:tensorflow:loss = 14.128294, step = 15400 (0.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.3353\n",
      "INFO:tensorflow:loss = 7.778256, step = 15500 (1.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.85\n",
      "INFO:tensorflow:loss = 16.643074, step = 15600 (0.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.523\n",
      "INFO:tensorflow:loss = 10.582421, step = 15700 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.714\n",
      "INFO:tensorflow:loss = 11.233977, step = 15800 (0.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.04\n",
      "INFO:tensorflow:loss = 13.819598, step = 15900 (0.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3208\n",
      "INFO:tensorflow:loss = 11.148033, step = 16000 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.9812\n",
      "INFO:tensorflow:loss = 11.729347, step = 16100 (1.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.911\n",
      "INFO:tensorflow:loss = 13.283863, step = 16200 (0.972 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 105.122\n",
      "INFO:tensorflow:loss = 9.701937, step = 16300 (0.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.995\n",
      "INFO:tensorflow:loss = 12.168016, step = 16400 (0.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.047\n",
      "INFO:tensorflow:loss = 6.608842, step = 16500 (0.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.169\n",
      "INFO:tensorflow:loss = 11.156133, step = 16600 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.551\n",
      "INFO:tensorflow:loss = 11.40318, step = 16700 (0.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.2634\n",
      "INFO:tensorflow:loss = 10.289389, step = 16800 (1.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.0512\n",
      "INFO:tensorflow:loss = 12.0915365, step = 16900 (1.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.5099\n",
      "INFO:tensorflow:loss = 12.094224, step = 17000 (1.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2241\n",
      "INFO:tensorflow:loss = 18.407843, step = 17100 (1.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.7457\n",
      "INFO:tensorflow:loss = 11.245224, step = 17200 (1.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.943\n",
      "INFO:tensorflow:loss = 7.4558754, step = 17300 (0.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.603\n",
      "INFO:tensorflow:loss = 11.494976, step = 17400 (0.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.706\n",
      "INFO:tensorflow:loss = 18.419968, step = 17500 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.873\n",
      "INFO:tensorflow:loss = 20.028692, step = 17600 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.743\n",
      "INFO:tensorflow:loss = 15.567975, step = 17700 (0.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.3386\n",
      "INFO:tensorflow:loss = 13.189549, step = 17800 (1.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.373\n",
      "INFO:tensorflow:loss = 12.098934, step = 17900 (0.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.8\n",
      "INFO:tensorflow:loss = 9.293236, step = 18000 (0.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5052\n",
      "INFO:tensorflow:loss = 12.511824, step = 18100 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.921\n",
      "INFO:tensorflow:loss = 17.016148, step = 18200 (0.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.039\n",
      "INFO:tensorflow:loss = 20.262604, step = 18300 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.246\n",
      "INFO:tensorflow:loss = 18.804157, step = 18400 (0.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.373\n",
      "INFO:tensorflow:loss = 13.622183, step = 18500 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.5986\n",
      "INFO:tensorflow:loss = 14.858263, step = 18600 (1.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.624\n",
      "INFO:tensorflow:loss = 16.263002, step = 18700 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.37\n",
      "INFO:tensorflow:loss = 16.07018, step = 18800 (0.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.817\n",
      "INFO:tensorflow:loss = 13.7078905, step = 18900 (0.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.955\n",
      "INFO:tensorflow:loss = 25.080719, step = 19000 (0.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.8762\n",
      "INFO:tensorflow:loss = 20.630781, step = 19100 (1.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.82\n",
      "INFO:tensorflow:loss = 11.318525, step = 19200 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.932\n",
      "INFO:tensorflow:loss = 14.053055, step = 19300 (0.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.117\n",
      "INFO:tensorflow:loss = 19.191826, step = 19400 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.271\n",
      "INFO:tensorflow:loss = 15.601475, step = 19500 (0.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.295\n",
      "INFO:tensorflow:loss = 11.518683, step = 19600 (0.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.828\n",
      "INFO:tensorflow:loss = 12.533488, step = 19700 (0.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.5872\n",
      "INFO:tensorflow:loss = 13.021003, step = 19800 (1.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.024\n",
      "INFO:tensorflow:loss = 14.109471, step = 19900 (0.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.663\n",
      "INFO:tensorflow:loss = 13.631842, step = 20000 (0.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.753\n",
      "INFO:tensorflow:loss = 14.283747, step = 20100 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.841\n",
      "INFO:tensorflow:loss = 14.959344, step = 20200 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.2176\n",
      "INFO:tensorflow:loss = 11.5687895, step = 20300 (1.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.387\n",
      "INFO:tensorflow:loss = 10.748497, step = 20400 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.221\n",
      "INFO:tensorflow:loss = 12.7551775, step = 20500 (0.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.76\n",
      "INFO:tensorflow:loss = 15.875589, step = 20600 (0.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.356\n",
      "INFO:tensorflow:loss = 14.741506, step = 20700 (0.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.981\n",
      "INFO:tensorflow:loss = 7.50026, step = 20800 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.001\n",
      "INFO:tensorflow:loss = 7.5512877, step = 20900 (0.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.538\n",
      "INFO:tensorflow:loss = 11.578213, step = 21000 (1.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.36\n",
      "INFO:tensorflow:loss = 6.8030457, step = 21100 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.474\n",
      "INFO:tensorflow:loss = 15.614553, step = 21200 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.271\n",
      "INFO:tensorflow:loss = 17.168873, step = 21300 (0.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.345\n",
      "INFO:tensorflow:loss = 13.514751, step = 21400 (0.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.6308\n",
      "INFO:tensorflow:loss = 11.293693, step = 21500 (1.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.129\n",
      "INFO:tensorflow:loss = 7.5188847, step = 21600 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.128\n",
      "INFO:tensorflow:loss = 19.572685, step = 21700 (0.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.3391\n",
      "INFO:tensorflow:loss = 15.049284, step = 21800 (1.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.35\n",
      "INFO:tensorflow:loss = 20.522448, step = 21900 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.749\n",
      "INFO:tensorflow:loss = 11.59299, step = 22000 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.488\n",
      "INFO:tensorflow:loss = 10.825242, step = 22100 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.035\n",
      "INFO:tensorflow:loss = 9.8503895, step = 22200 (1.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.621\n",
      "INFO:tensorflow:loss = 21.588346, step = 22300 (0.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.133\n",
      "INFO:tensorflow:loss = 22.331018, step = 22400 (0.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.73\n",
      "INFO:tensorflow:loss = 11.453539, step = 22500 (0.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.547\n",
      "INFO:tensorflow:loss = 14.500283, step = 22600 (0.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.452\n",
      "INFO:tensorflow:loss = 11.615902, step = 22700 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.0113\n",
      "INFO:tensorflow:loss = 12.304678, step = 22800 (1.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.775\n",
      "INFO:tensorflow:loss = 11.900099, step = 22900 (0.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.046\n",
      "INFO:tensorflow:loss = 17.697866, step = 23000 (0.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.8983\n",
      "INFO:tensorflow:loss = 6.173317, step = 23100 (1.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.317\n",
      "INFO:tensorflow:loss = 23.614128, step = 23200 (0.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.388\n",
      "INFO:tensorflow:loss = 11.252157, step = 23300 (0.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.203\n",
      "INFO:tensorflow:loss = 14.536034, step = 23400 (0.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.058\n",
      "INFO:tensorflow:loss = 15.72447, step = 23500 (0.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.4883\n",
      "INFO:tensorflow:loss = 17.124838, step = 23600 (1.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.739\n",
      "INFO:tensorflow:loss = 10.806322, step = 23700 (0.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.202\n",
      "INFO:tensorflow:loss = 12.626049, step = 23800 (0.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.654\n",
      "INFO:tensorflow:loss = 11.322195, step = 23900 (0.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.399\n",
      "INFO:tensorflow:loss = 13.769504, step = 24000 (0.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.685\n",
      "INFO:tensorflow:loss = 12.994926, step = 24100 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.0653\n",
      "INFO:tensorflow:loss = 12.594311, step = 24200 (1.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.5652\n",
      "INFO:tensorflow:loss = 16.843922, step = 24300 (1.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.447\n",
      "INFO:tensorflow:loss = 14.946555, step = 24400 (0.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.2906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 17.31389, step = 24500 (1.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.832\n",
      "INFO:tensorflow:loss = 10.417821, step = 24600 (0.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.166\n",
      "INFO:tensorflow:loss = 10.962695, step = 24700 (0.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.7438\n",
      "INFO:tensorflow:loss = 20.863811, step = 24800 (1.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.536\n",
      "INFO:tensorflow:loss = 17.292059, step = 24900 (0.690 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/tmpc92phuw8/bow_sparse/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13.349406.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-19-15:34:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpc92phuw8/bow_sparse/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-19-15:34:05\n",
      "INFO:tensorflow:Saving dict for global step 25000: accuracy = 0.81652, accuracy_baseline = 0.5, auc = 0.8887907, auc_precision_recall = 0.8897852, average_loss = 0.6738792, global_step = 25000, label/mean = 0.5, loss = 67.387924, precision = 0.81289047, prediction/mean = 0.5050249, recall = 0.82232\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25000: /tmp/tmpc92phuw8/bow_sparse/model.ckpt-25000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpc92phuw8/bow_sparse/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qAHrTDbvq99"
   },
   "source": [
    "Визуализируем, какие слова вносят наибольший вклад в результат предсказания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1098,
     "status": "ok",
     "timestamp": 1523274052541,
     "user": {
      "displayName": "Julian Eisenschlos",
      "photoUrl": "//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg",
      "userId": "112692138304087361987"
     },
     "user_tz": 180
    },
    "id": "R7iy_8MAvq9-",
    "outputId": "2eaeb25d-7f32-4ceb-c676-c6ef8093324a"
   },
   "outputs": [],
   "source": [
    "weights = classifier.get_variable_value('linear/linear_model/x/weights').flatten()\n",
    "sorted_indexes = np.argsort(weights)\n",
    "extremes = np.concatenate((sorted_indexes[-8:], sorted_indexes[:8]))\n",
    "extreme_weights = sorted([(weights[i], word_inverted_index[i]) for i in extremes])\n",
    "\n",
    "y_pos = np.arange(len(extreme_weights))\n",
    "plt.bar(y_pos, [pair[0] for pair in extreme_weights], align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, [pair[1] for pair in extreme_weights], rotation=45, ha='right')\n",
    "plt.ylabel('Weight')\n",
    "plt.title('Most significant tokens') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptorLYCwArTp"
   },
   "source": [
    "### Embeddings\n",
    "\n",
    "Теперь добавим в наше решение эмбеддинги слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 8979
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 274050,
     "status": "ok",
     "timestamp": 1520355496237,
     "user": {
      "displayName": "Sebastian Ruder",
      "photoUrl": "//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg",
      "userId": "101962136952284559776"
     },
     "user_tz": 0
    },
    "id": "IpJrW8_zvq-D",
    "outputId": "2d3d6041-1ac3-468e-cd8c-9760c558f30e"
   },
   "outputs": [],
   "source": [
    "word_embedding_column = tf.feature_column.embedding_column(column, dimension=embedding_size)\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[100],\n",
    "    feature_columns=[word_embedding_column], \n",
    "    model_dir=os.path.join(model_dir, 'bow_embeddings'))\n",
    "train_and_evaluate(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9q7qfXrvq-J"
   },
   "source": [
    "Визуализируем эмбеддинги при помощи [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)\n",
    "\n",
    "В TensorFlow для этого есть [standalone projector visualizer](http://projector.tensorflow.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ujVD4Yv0vq-J"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dir, 'metadata.tsv'), 'w', encoding=\"utf-8\") as f:\n",
    "    f.write('label\\n')\n",
    "    for index in range(0, vocab_size):\n",
    "        f.write(word_inverted_index[index] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9SKqlRpvq-N"
   },
   "source": [
    "### Convolutions\n",
    "\n",
    "Применим 1d свертки по словам, чтобы предсказывать лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdIuS0-65eNB"
   },
   "source": [
    "### Создание кастомного estimator`а\n",
    "\n",
    "Фреймворк `tf.estimator`предоставляет высокоуровневые API для обучения ML моделей,методы `train()`, `evaluate()` и `predict()`, автоматическое сохранение чекпоинтов, методы загрузки, инициализации, сервинга модели, создание сессии и графа из коробки. \n",
    "\n",
    "Одно из важных преимуществ использования именно эстиматоров состоит в том, что один и тот же код можно использовать без изменений на CPU, GPU и даже распределенной конфигурации GPU.\n",
    "\n",
    "В `tf` есть несколько простых стандартных эстиматоров. Но в большинстве случаев удобнее написть свой кастомный эстиматор, где можно использовать любую архитектуру нейронной сети. [Тут](https://www.tensorflow.org/extend/estimators) можно почитать хорошое объяснение про то как создавать кастомные эстиматоры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1314,
     "status": "ok",
     "timestamp": 1520355499529,
     "user": {
      "displayName": "Sebastian Ruder",
      "photoUrl": "//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg",
      "userId": "101962136952284559776"
     },
     "user_tz": 0
    },
    "id": "Wf-sGICDejgx",
    "outputId": "3013573a-b39f-426b-80d3-0630b7107149"
   },
   "outputs": [],
   "source": [
    "head = tf.contrib.estimator.binary_classification_head()\n",
    "\n",
    "def cnn_model_fn(features, labels, mode, params):    \n",
    "    input_layer = tf.contrib.layers.embed_sequence(\n",
    "        features['x'], vocab_size, embedding_size,\n",
    "        initializer=params['embedding_initializer'])\n",
    "    \n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    dropout_emb = tf.layers.dropout(inputs=input_layer, \n",
    "                                    rate=0.2, \n",
    "                                    training=training)\n",
    "\n",
    "    conv = tf.layers.conv1d(\n",
    "        inputs=dropout_emb,\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Global Max Pooling\n",
    "    pool = tf.reduce_max(input_tensor=conv, axis=1)\n",
    "    \n",
    "    hidden = tf.layers.dense(inputs=pool, units=250, activation=tf.nn.relu)\n",
    "    \n",
    "    dropout_hidden = tf.layers.dropout(inputs=hidden, \n",
    "                                       rate=0.2, \n",
    "                                       training=training)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dropout_hidden, units=1)\n",
    "    \n",
    "    # This will be None when predicting\n",
    "    if labels is not None:\n",
    "        labels = tf.reshape(labels, [-1, 1])\n",
    "        \n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    \n",
    "    def _train_op_fn(loss):\n",
    "        return optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "\n",
    "    return head.create_estimator_spec(\n",
    "        features=features,\n",
    "        labels=labels,\n",
    "        mode=mode,\n",
    "        logits=logits, \n",
    "        train_op_fn=_train_op_fn)\n",
    "  \n",
    "params = {'embedding_initializer': tf.random_uniform_initializer(-1.0, 1.0)}\n",
    "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
    "                                        model_dir=os.path.join(model_dir, 'cnn'),\n",
    "                                        params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 8979
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 197228,
     "status": "ok",
     "timestamp": 1520355697562,
     "user": {
      "displayName": "Sebastian Ruder",
      "photoUrl": "//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg",
      "userId": "101962136952284559776"
     },
     "user_tz": 0
    },
    "id": "_ndMYmQ5qNk2",
    "outputId": "8a8ec2d2-d467-4e0d-a964-3eaba1258f50"
   },
   "outputs": [],
   "source": [
    "train_and_evaluate(cnn_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-wDDowAvq-X"
   },
   "source": [
    "### Предобученные вектора\n",
    "\n",
    "Попробуем исользовать предобученные эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116108,
     "status": "ok",
     "timestamp": 1520355813761,
     "user": {
      "displayName": "Sebastian Ruder",
      "photoUrl": "//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg",
      "userId": "101962136952284559776"
     },
     "user_tz": 0
    },
    "id": "7zbWoklJtzRP",
    "outputId": "a03a4db2-cc6a-4a43-8f5d-c4aeac7c00be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-02-19 15:34:09--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving proxy.tcsbank.ru (proxy.tcsbank.ru)... 10.218.11.51, 10.218.6.48, 10.218.6.49, ...\n",
      "Connecting to proxy.tcsbank.ru (proxy.tcsbank.ru)|10.218.11.51|:8080... connected.\n",
      "Proxy request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2019-02-19 15:34:10--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to proxy.tcsbank.ru (proxy.tcsbank.ru)|10.218.11.51|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip         83%[===============>    ] 688.10M   669KB/s    eta 3m 40s "
     ]
    }
   ],
   "source": [
    "if not os.path.exists('glove.6B.zip'):\n",
    "    ! wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "if not os.path.exists('glove.6B.50d.txt'):\n",
    "    ! unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7587,
     "status": "ok",
     "timestamp": 1520355821435,
     "user": {
      "displayName": "Sebastian Ruder",
      "photoUrl": "//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg",
      "userId": "101962136952284559776"
     },
     "user_tz": 0
    },
    "id": "S5m1Fkj4vq-Y",
    "outputId": "5c525191-ae6f-45aa-9047-ea0510746451"
   },
   "outputs": [],
   "source": [
    "def load_glove_embeddings(path):\n",
    "    embeddings = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            w = values[0]\n",
    "            vectors = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[w] = vectors\n",
    "\n",
    "    embedding_matrix = np.random.uniform(-1, 1, size=(vocab_size, embedding_size))\n",
    "    num_loaded = 0\n",
    "    for w, i in word_index.items():\n",
    "        v = embeddings.get(w)\n",
    "        if v is not None and i < vocab_size:\n",
    "            embedding_matrix[i] = v\n",
    "            num_loaded += 1\n",
    "    print('Successfully loaded pretrained embeddings for '\n",
    "          f'{num_loaded}/{vocab_size} words.')\n",
    "    embedding_matrix = embedding_matrix.astype(np.float32)\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix = load_glove_embeddings('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7LwE2M5kKY44"
   },
   "source": [
    "Для этого будем подавать в эстиматор инициализатор эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 8962
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 206590,
     "status": "ok",
     "timestamp": 1520356028896,
     "user": {
      "displayName": "Sebastian Ruder",
      "photoUrl": "//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg",
      "userId": "101962136952284559776"
     },
     "user_tz": 0
    },
    "id": "1uWwWkqjFbRE",
    "outputId": "466bc012-df13-428d-d91d-32aae3c51756"
   },
   "outputs": [],
   "source": [
    "def my_initializer(shape=None, dtype=tf.float32, partition_info=None):\n",
    "    assert dtype is tf.float32\n",
    "    return embedding_matrix\n",
    "\n",
    "params = {'embedding_initializer': my_initializer}\n",
    "cnn_pretrained_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
    "                                        model_dir=os.path.join(model_dir, 'cnn_pretrained'),\n",
    "                                        params=params)\n",
    "train_and_evaluate(cnn_pretrained_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5l6_C5uTVk4"
   },
   "source": [
    "## Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKVCyX68vq-c"
   },
   "source": [
    "### Запуск TensorBoard\n",
    "\n",
    "Проанализируем, какие метрии мы получили\n",
    "\n",
    "Чтобы запустить tensorboard, нужно выполнить команду\n",
    "```bash\n",
    "> tensorboard --logdir={model_dir}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2dw3iYOSuNg"
   },
   "source": [
    "### Предсказания модели\n",
    "\n",
    "Чтобы получить предсказания модели на новых примерах можно использовать метод `predict` у объекта `Estimator`, \n",
    "который подгружает последний сохранненный checkpoint для каждой модели и прогоняет через можель данные новых примеров. \n",
    "\n",
    "Но перед подачей данных в модель их нужно очистить, токенизировать и отобразить каждое слова в соответствущий ему индекс.\n",
    "\n",
    "[!] Наличие только файла с сохраненной моделью не является достаточным, чтобы сгенерировать предсказания, т.к. код для создания эстиматора используется для сопоставления сохраненных весов и соответствующих тензоров в графе, поэтому хорошей практикой является сохранение модели в одной папке с кодом, который используется для ее создания. \n",
    "\n",
    "[!] Создание файла с моделью, которую можно полностью восстановить из файла возможно при помощи класса [SavedModel](https://www.tensorflow.org/programmers_guide/saved_model#using_savedmodel_with_estimators), \n",
    "который обычно используется при сохранении модели для сервинга [TensorFlow Serving](https://github.com/tensorflow/serving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1523274345221,
     "user": {
      "displayName": "Julian Eisenschlos",
      "photoUrl": "//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg",
      "userId": "112692138304087361987"
     },
     "user_tz": 180
    },
    "id": "34K8O0bTNj-b",
    "outputId": "eef27d40-63ce-4863-8720-7669a39ba03a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def text_to_index(sentence):\n",
    "    # Remove punctuation characters except for the apostrophe\n",
    "    translator = str.maketrans('', '', string.punctuation.replace(\"'\", ''))\n",
    "    tokens = sentence.translate(translator).lower().split()\n",
    "    return np.array([1] + [word_index[t] if t in word_index else oov_id for t in tokens])\n",
    "\n",
    "def print_predictions(sentences):\n",
    "    indexes = [text_to_index(sentence) for sentence in sentences]\n",
    "    x = sequence.pad_sequences(indexes, \n",
    "                               maxlen=sentence_size, \n",
    "                               truncating='post',\n",
    "                               padding='post',\n",
    "                               value=pad_id)\n",
    "    length = np.array([min(len(x), sentence_size) for x in indexes])\n",
    "    predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": x, \"len\": length}, shuffle=False)\n",
    "    predictions = {}\n",
    "    for path, classifier in all_classifiers.items():\n",
    "        predictions[path] = [p['logistic'][0] for p in classifier.predict(input_fn=predict_input_fn)]\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        print(sentence)\n",
    "        for path in all_classifiers:\n",
    "            print(\"\\t{} {}\".format(path, predictions[path][idx]))\n",
    "            \n",
    "print_predictions([\n",
    "    'I really liked the movie!',\n",
    "    'Hated every second of it...'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PuycPjrrvq-d"
   },
   "source": [
    "### Список для чтения\n",
    "\n",
    "Интуиция по работе CNN:\n",
    "* Colah's [Understanding convolutions](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)\n",
    "* Colah's [Conv Nets: A Modular Perspective](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/)\n",
    "* [CS231n](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "Туториалы:\n",
    "* Как использовать TensorFlow Estimator API в различных задачах [tf-estimator-tutorials](https://github.com/GoogleCloudPlatform/tf-estimator-tutorials)\n",
    "\n",
    "Со звездочкой:\n",
    "* [Back Propagation in Convolutional Neural Networks — Intuition and Code](https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199)\n",
    "* [Dilated Convolutions and Kronecker Factored Convolutions](https://www.inference.vc/dilated-convolutions-and-kronecker-factorisation/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "nlp_estimators.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
